{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFNET\n",
    "## Engenharia de Prompts para Ciência de Dados [24E4_4] - AT\n",
    "### Rodrigo Avila - 22/12/2024\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 1) Arquitetura da Solução\n",
    "Desenhe a arquitetura da solução com o programa da sua escolha. A arquitetura deve indicar os pontos de processamento de informação, LLMs utilizados, bases de dados (parquets, jsons e faiss), arquivos de configuração (yaml), abas do dashboard e suas funcionalidades.\n",
    "\n",
    "#### a) Exporte a arquitetura para o arquivo pdf importado no sistema.\n",
    "TODO\n",
    "\n",
    "#### b) Descreva a arquitetura, explicando seus pontos importantes.\n",
    "TODO\n",
    "\n",
    "#### c) Descreva o funcionamento de LLMs e como isso pode ser utilizado para atividades de sumarização.\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 2: Criação de Textos com LLMs\n",
    "\n",
    "Utilize a sua conta no “poe.com” para gerar um texto curto (2 parágrafos) que explique a Câmara dos Deputados. Execute o mesmo prompt com 3 LLMs diferentes (claude, gemini e chatgpt) e:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Explique as vantagens e desvantagens dos três LLMs escolhidos.\n",
    "\n",
    "Claude:\n",
    "- Vantagens:\n",
    "    - Ética e segurança como foco central: Claude é projetado para minimizar respostas que possam ser prejudiciais ou tóxicas, priorizando interações seguras.\n",
    "    - Foco em compliance: Útil para casos em que a conformidade com regulamentações e padrões éticos é essencial.\n",
    "- Desvantagens:\n",
    "    - Menor flexibilidade em tópicos técnicos: Pode não ser tão robusto quanto ChatGPT ou Gemini em tarefas altamente técnicas.\n",
    "    - Menor capacidade multimodal \n",
    "\n",
    "Gemini:\n",
    "- Vantagens:\n",
    "    - Capacidade multimodal: Gemini pode lidar com entradas de texto e imagem, o que pode ser útil para tarefas que envolvem múltiplos modos de entrada.\n",
    "    - Flexibilidade em tópicos técnicos: Pode ser mais robusto em termos de conhecimento técnico e especializado.\n",
    "    - Indicado em encontrar eventos mais recentes\n",
    "- Desvantagens:\n",
    "    - Menor foco em compliance: Pode gerar respostas que não são adequadas para ambientes regulamentados ou sensíveis.\n",
    "    - Em geral tem menos profundidade nas respostas ao se comparar com ChatGPT\n",
    "\n",
    "ChatGPT:\n",
    "- Vantagens:\n",
    "    - Profundidade nas respostas: ChatGPT pode fornecer respostas mais detalhadas e completas em comparação com outros modelos.\n",
    "    - Versatilidade: É um dos modelos mais amplamente usados, com excelente desempenho em tarefas criativas, técnicas e educacionais.\n",
    "    - Costuma ser melhor na parte criativa\n",
    "- Desvantagens:\n",
    "    - Custos de uso: Em geral, pode ser mais caro de usar em comparação com outros modelos.\n",
    "    - Menor foco em compliance: Pode gerar respostas que não são adequadas para ambientes regulamentados ou sensíveis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Argumente sobre a diferença entre a resposta dos 3 LLMs\n",
    "\n",
    "Claude: Foi o que teve a resposta mais \"rasa\" e menos detalhada, focando mais em aspectos gerais, sem entrar em muitos detalhes específicos.\n",
    "\n",
    "Gemini: Apresentou uma resposta mais detalhada e com mais informações sobre a Câmara dos Deputados, incluindo aspectos como a composição, funções e processos.\n",
    "\n",
    "ChatGPT: Fornecendo uma resposta mais abrangente e detalhada, com uma explicação mais completa sobre a Câmara dos Deputados, acredito que abordou todos os aspectos necessários e importantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Justifique a escolha da resposta final\n",
    "Para o \"use case\" em questão, a melhor resposta foi a do Chat GPT, pois foi uma pergunta bem genérica \"Explique a Câmara dos Deputados\", e nesse caso, acredito que a profundidade da resposta e o detalhamento é o mais importante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Atualize o prompt do LLM final para gerar um arquivo data/config.yaml com a resposta final (chave: overview_summary).\n",
    "Obs: verificar arquivo /data/config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 3: Processamento dos dados de deputados\n",
    "\n",
    "#### a) Colete e salve os dados dos deputados atuais da câmara no arquivo data/deputados.parquet através da url: url_base+/deputados\n",
    "Verificar src/dataprep.py\n",
    "\n",
    "#### b) Executar prompt para criar o código que gere um gráfico de pizza com o total e o percentual de deputados de cada partido, salvo em 'docs/distribuicao_deputados.png\n",
    "Verificar src/dataprep.py\n",
    "\n",
    "#### c) Utilize os elementos de prompts dados, persona e exemplos para instruir o LLM. Explique o objetivo de cada elemento, avalie a resposta e salve-a em data/insights_distribuicao_deputados.json.\n",
    "\n",
    "O objetivo de cada elemento é:\n",
    "\n",
    "- Dados: Ao fornecer os dados sobre a distribuição de deputados por partido e estado, o LLM pode usar essas informações para gerar insights e análises mais precisas e relevantes.\n",
    "- Persona: Ao utilizar um persona, a LLM trás uma resposta especializada, focada em um perfil específico, o que pode ser útil para obter insights mais específicos e detalhados, atendendo melhor a necessidade do usuário.\n",
    "- Exemplos: Utilizado para informar a LLM como seriam os dados e também o formato que ela deveria responder a pergunta (json).\n",
    "\n",
    "Com relação a resposta, acredito que foi bem precisa, dentro do padrão esperado, fornecendo informações relevantes sobre a distribuição de deputados por partido. Não notei nenhuma alucionação, a resposta foi um json válido e bem estruturado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 4: Processamento dos dados de deputados\n",
    "Implemente em dataprep.py uma função que colete as informações das despesas dos deputados atuais da câmara dos deputados no período de referência da solução (use a url: url_base+/deputados/{id}/despesas)\n",
    "\n",
    "#### a) Agrupe os dados de despesas por dia, deputado e tipo de despesa e salve num arquivo parquet (data/serie_despesas_diárias_deputados.parquet).\n",
    "Verificar src/dataprep.py\n",
    "\n",
    "#### b) Utilizando a técnica de prompt-chaining, crie um prompt que instrua o LLM a gerar um código python que analise os dados das despesas dos deputados. Peça para o LLM até 3 análises. Indique ao LLM quais dados estão disponíveis e o respectivo arquivo (salvo em a)) e execute as análises.\n",
    "\n",
    "A ténica prompt-chaining é utilizada para guiar o LLM em uma sequência de prompts, onde cada prompt é baseado na resposta do prompt anterior, em chats onde se tem memória, o LLM consegue revisar o código anterior completamente e então atualizar, como se fosse o prompt-chaining, inclusive, o ChatGPT agora parece ter uma espécie de IDE integrada, bem interessante, cada prompt ele revisa o código anterior completamente e então atualiza, aplicando a técnica de prompt-chaining automaticamente.\n",
    "\n",
    "\n",
    "![ex4_pc_1](/Users/rodrigo/Dev/infnet/4SEM/engenharia_de_prompt/AT/images/ex4_prompt_chaining_1.png)\n",
    "![ex4_pc_2](/Users/rodrigo/Dev/infnet/4SEM/engenharia_de_prompt/AT/images/ex4_prompt_chaining_2.png)\n",
    "![ex4_pc_3](/Users/rodrigo/Dev/infnet/4SEM/engenharia_de_prompt/AT/images/ex4_prompt_chaining_3.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, execução do código gerado pelo LLM para análise dos dados das despesas dos deputados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"biggest_expense\": {\n",
      "        \"tipoDespesa\": \"LOCAÇÃO OU FRETAMENTO DE AERONAVES\",\n",
      "        \"dataDocumento\": \"2024-09-04T00:00:00\",\n",
      "        \"valorDocumento\": 85000.0,\n",
      "        \"nomeFornecedor\": \"R L FERREIRA - SERVIÇOS E AGENCIAMENTO LTDA\",\n",
      "        \"id\": 220675,\n",
      "        \"nome\": \"Antônio Doido\",\n",
      "        \"siglaPartido\": \"MDB\"\n",
      "    },\n",
      "    \"lowest_expense\": {\n",
      "        \"tipoDespesa\": \"PASSAGEM AÉREA - SIGEPA\",\n",
      "        \"dataDocumento\": \"2024-08-09T12:00:00\",\n",
      "        \"valorDocumento\": -3113.17,\n",
      "        \"nomeFornecedor\": \"TAM\",\n",
      "        \"id\": 74253,\n",
      "        \"nome\": \"Julio Lopes\",\n",
      "        \"siglaPartido\": \"PP\"\n",
      "    },\n",
      "    \"most_frequent_expense\": \"COMBUSTÍVEIS E LUBRIFICANTES.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def analyze_expenses(file_path, output_json_path):\n",
    "    # Read the parquet file into a pandas DataFrame\n",
    "    dataframe = pd.read_parquet(file_path)\n",
    "\n",
    "    # First: Find the expense with the biggest value\n",
    "    biggest_expense = dataframe.loc[dataframe['valorDocumento'].idxmax()]\n",
    "\n",
    "    # Second: Find the expense with the lowest value\n",
    "    lowest_expense = dataframe.loc[dataframe['valorDocumento'].idxmin()]\n",
    "\n",
    "    # Third: Find the most frequent expense type\n",
    "    most_frequent_expense = dataframe['tipoDespesa'].mode()[0]\n",
    "\n",
    "    # Prepare the analysis results with native Python types\n",
    "    analysis = {\n",
    "        \"biggest_expense\": {\n",
    "            \"tipoDespesa\": str(biggest_expense['tipoDespesa']),\n",
    "            \"dataDocumento\": str(biggest_expense['dataDocumento']),\n",
    "            \"valorDocumento\": float(biggest_expense['valorDocumento']),\n",
    "            \"nomeFornecedor\": str(biggest_expense['nomeFornecedor']),\n",
    "            \"id\": int(biggest_expense['id']),\n",
    "            \"nome\": str(biggest_expense['nome']),\n",
    "            \"siglaPartido\": str(biggest_expense['siglaPartido'])\n",
    "        },\n",
    "        \"lowest_expense\": {\n",
    "            \"tipoDespesa\": str(lowest_expense['tipoDespesa']),\n",
    "            \"dataDocumento\": str(lowest_expense['dataDocumento']),\n",
    "            \"valorDocumento\": float(lowest_expense['valorDocumento']),\n",
    "            \"nomeFornecedor\": str(lowest_expense['nomeFornecedor']),\n",
    "            \"id\": int(lowest_expense['id']),\n",
    "            \"nome\": str(lowest_expense['nome']),\n",
    "            \"siglaPartido\": str(lowest_expense['siglaPartido'])\n",
    "        },\n",
    "        \"most_frequent_expense\": str(most_frequent_expense)\n",
    "    }\n",
    "\n",
    "    # Write the analysis to a JSON file\n",
    "    with open(output_json_path, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(analysis, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    return analysis\n",
    "\n",
    "# Define the file paths\n",
    "file_path = 'data/serie_despesas_diárias_deputados.parquet'\n",
    "output_json_path = 'data/despesas_deputados.json'\n",
    "\n",
    "# Perform the analysis\n",
    "results = analyze_expenses(file_path, output_json_path)\n",
    "\n",
    "# Print the analysis results\n",
    "print(json.dumps(results, indent=4, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Utilize os resultados das 3 análises para criar um prompt usando a técnica de Generated Knowledge para instruir o LLM a gerar insights. Salve o resultado como um JSON (data/insights_despesas_deputados.json)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar a imagem ex4_generated_knowledge_1.png para visualizar o prompt.\n",
    "\n",
    "![ex4_generated_knowledge_1](/Users/rodrigo/Dev/infnet/4SEM/engenharia_de_prompt/AT/images/ex4_generated_knowledge_1.png)\n",
    "![ex4_generated_knowledge_2](/Users/rodrigo/Dev/infnet/4SEM/engenharia_de_prompt/AT/images/ex4_generated_knowledge_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 5) Processamento dos dados de proposições\n",
    "\n",
    "#### a) Coletar um total de 10 proposiçoes por tema e salvar em data/proposicoes_deputados.parquet\n",
    "Verificar src/dataprep.py\n",
    "\n",
    "#### b) Utilize a sumarização por chunks para resumir as proposições tramitadas no período de referência. Avalie a resposta e salve-a em data/sumarizacao_proposicoes.json\n",
    "Verificar src/dataprep.py\n",
    "\n",
    "Verificar data/sumarizacao_proposicoes.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 6) Dashboards com Chain-of-thoughts\n",
    "\n",
    "Utilize 3 etapas de Chain-of-Thought prompting para escrever o código inicial do dashboard, destacando as abas Overview, Despesas e Proposições. Explique o objetivo de cada prompt na evolução do código até o arquivo dashboard.py final:\n",
    "\n",
    "* A aba Overview deve possuir um título e descrição da solução de sua escolha.\n",
    "* O painel deve mostrar o texto sumarizado em config.yaml\n",
    "* O painel deve mostrar o gráfico de barras em docs/distribuicao_deputados.png\n",
    "* O painel deve mostrar os insights do LLM sobre a distribuição de deputados em data/insights_distribuicao_deputados.json\n",
    "\n",
    "#### Prompt 1:\n",
    "\n",
    "O objeto do primeiro prompt foi contextualizar a LLM pedindo para que ela fizesse um código simples e funcional para um app streamlit\n",
    "\n",
    "![ex6_prompt_1](/Users/rodrigo/Dev/infnet/4SEM/engenharia_de_prompt/AT/images/ex6_chain_of_thougts_1.png)\n",
    "\n",
    "#### Prompt 2:\n",
    "\n",
    "O objetivo do segundo prompt foi criar as aba Overview, Despesas e Proposições e adicionar o título e a descrição na Aba Overview\n",
    "\n",
    "![ex6_prompt_2](/Users/rodrigo/Dev/infnet/4SEM/engenharia_de_prompt/AT/images/ex6_chain_of_thougts_2.png)\n",
    "\n",
    "#### Prompt 3:\n",
    "\n",
    "O objetivo do terceiro prompot foi adicionar conteúdo para a aba Overview, incluindo os arquivos generados nos exercícios anteriores\n",
    "\n",
    "![ex6_prompt_3](/Users/rodrigo/Dev/infnet/4SEM/engenharia_de_prompt/AT/images/ex6_chain_of_thougts_3.png)\n",
    "\n",
    "Dessa forma, de maneira incrimental, utilizando a técnica de Chain-of-Thoughts, foi possível criar um dashboard funcional e com informações relevantes para o usuário. O código ficou 100% funcional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 7) Dashboards com Batch-prompting\n",
    "\n",
    "Utilize a técnica de Batch-prompting para escrever o código streamlit que preencha as abas Despesas e Proposições do código em dashboard.py. O prompt deve descrever com detalhes cada aba para geração de:\n",
    "\n",
    "* Aba Despesas deve mostrar os insights sobre as despesas dos deputados (data/insights_despesas_deputados.json)\n",
    "* Aba Despesas deve conter um st.selectbox para seleção do deputado.\n",
    "* Aba Despesas deve mostrar gráfico de barras com a série temporal de despesas do deputado selecionado (data/serie_despesas_diárias_deputados.parquet).\n",
    "* O painel deve mostrar uma tabela com os dados das proposições (data/proposicoes_deputados.parquet)\n",
    "* O painel deve mostrar o resumo das proposições em (data/sumarizacao_proposicoes.json)\n",
    "\n",
    "#### Prompt (parte 1):\n",
    "\n",
    "![ex7_batch_prompting_1](/Users/rodrigo/Dev/infnet/4SEM/engenharia_de_prompt/AT/images/ex7_batch_prompting_1.png)\n",
    "\n",
    "#### Prompt (parte 2):\n",
    "\n",
    "![ex7_batch_prompting_2](/Users/rodrigo/Dev/infnet/4SEM/engenharia_de_prompt/AT/images/ex7_batch_prompting_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare o resultado dos códigos gerados pelas técnicas de Chain-of-Thoughts e Batch-prompting\n",
    "\n",
    "O resultado da técnica Chain-of-Thougts foi 100% funcional, gerando um código que atendeu a todos os requisitos do exercício.\n",
    "\n",
    "Surpreendentemente, o resultado da técnica Batch-prompting também funcionou perfeitamente, mesmo sendo mais complexo, enviando tudo de uma vez e com o requisito de carregamento de dataframes para gerar plots.\n",
    "\n",
    "Ambas técnicas são muito eficientes e funcionais, o que muda é a forma de interação com o LLM, onde no Chain-of-Thoughts é de maneira incremental e no Batch-prompting é de maneira simultânea, sendo bem mais complexo, eu demorei bastante tempo para conseguir escrever o Batch-Prompting, acredito que o Chain-of-Thoughts é mais fácil de escrever e mais intuitivo.\n",
    "\n",
    "Conclusão: Chain-of-Thougts é mais simples e intuitivo, porém depende de mais interações com a LLM. Batch-prompting é mais complexo, porém mais eficiente. Desde que o Batch-Prompting seja feito na medida certa, a diferença no resultado esperado é pequena."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 8 Assistente online com base vetorial\n",
    "\n",
    "Adicione ao código da aba Proposições uma interface para chat com um assistente virtual especialista em câmara dos deputados. As informações coletadas dos deputados, despesas e proposições (e suas sumarizações) devem ser vetorizadas usando o modelo \"neuralmind/bert-base-portuguese-cased\" para armazenamento na base vetorial FAISS. O prompt do sistema para o assistente virtual deve ser feito com a técnica Self-Ask:\n",
    "\n",
    "> Observação: st.chat_message() e st.chat_input() estava bugando dentro de uma tab (st.tab()), então eu tomei a liberdade de colocar o chat fora da tab, espero que não seja um problema :(\n",
    "\n",
    "#### a) Explique como a técnica de self-ask pode ser utilizada nesse contexto.\n",
    "A técnica self-ask pode ser utilizada no contexto atual, pois é uma ténica que auxilia o LLM a responder perguntas complexas, fazendo com que ele mesmo se faça perguntas para obter informações adicionais. \n",
    "\n",
    "No caso do assistente virtual especialista em câmara dos deputados, a técnica self-ask pode ser utilizada para guiar o LLM a fornecer informações mais detalhadas e relevantes sobre os deputados, despesas e proposições, ajudando a fornecer respostas mais precisas e completas aos usuários. \n",
    "\n",
    "#### b) Avalie o resultado do modelo para as seguintes perguntas:\n",
    "\n",
    "Infezlimente eu costumo fazer meus prompts sempre em inglês, o que acabou gerando os arquivos em inglês e acabou prejudicando na hora da busca vetorial, só percebi esse detalhe agora. De qualquer forma a implementação foi feita.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) Qual é o partido político com mais deputados na câmara?\n",
    "O LLM não conseguiu responder essa pergunta, acredito que devido ao fato dos dados em json estarem com as chaves em português"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) Qual é o deputado com mais despesas na câmara?\n",
    "Apesar de ter essa informação, acredito que a LLM não conseguiu responder porque o json que continha essa informação estava todo em inglês, o que acabou prejudicando na busca vetorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) Qual é o tipo de despesa mais declarada pelos deputados da câmara?\n",
    "Apesar de ter essa informação, acredito que a LLM não conseguiu responder porque o json que continha essa informação estava todo em inglês, o que acabou prejudicando na busca vetorial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) Quais são as informações mais relevantes sobre as proposições que falam de Economia?\n",
    "\n",
    "A resposta foi bem satisfatória, de todas as proposições que estavam na minha base vetorial, ele citou as duas que tinha haver com economia, acredito que a busca vetorial foi bem sucedida.\n",
    "\n",
    "Parte da resposta da LLM:\n",
    "\n",
    "\"PL 139/2024\n",
    "* Ementa: Estabelece normas gerais em contratos de seguro privado e revoga dispositivos do Código Civil, do Código Comercial Brasileiro e do Decreto-Lei nº 73 de 1966.\n",
    "* Relevância Econômica: Trata de regulamentações no setor de seguros privados, um segmento importante para a economia, por envolver proteção financeira, segurança de investimentos e estabilidade no mercado.\n",
    "\n",
    "PLP 140/2007\n",
    "* Ementa: Altera a Lei Complementar nº 101, de 4 de maio de 2000 - Lei de Responsabilidade Fiscal, para suspender temporariamente o pagamento das dívidas assumidas com a União dos Municípios que se encontrem em situação de emergência ou calamidade pública.\n",
    "* Relevância Econômica: Impacta diretamente a gestão fiscal e financeira dos municípios, influenciando a capacidade de investimento e recuperação econômica em situações críticas.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O LLM encontrou proposições, porém não havia nenhuma relacionada a economia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5) Quais são as informações mais relevantes sobre as proposições que falam de 'Ciência, Tecnologia e Inovação'?\n",
    "\n",
    "Novamente, a resposta foi bem satisfatória, de todas as proposições da minha base vetorial, tinha apenas uma relacionada a Ciência, Tecnologia e Inovação, e a LLM conseguiu encontrar.\n",
    "\n",
    "Parte da resposta da LLM:\n",
    "\n",
    "\"PL 139/2007\n",
    "* Ementa: Altera a Lei nº 9.998, de 17 de agosto de 2000, que institui o Fundo de Universalização dos Serviços de Telecomunicações (FUST) para determinar a aplicação de recursos em educação e em ciência e tecnologia.\n",
    "* Relevância:\n",
    "  * Envolve a destinação de recursos financeiros do FUST para promover o desenvolvimento em educação e nas áreas de ciência e tecnologia.\n",
    "  * Contribui para o fortalecimento da infraestrutura tecnológica e científica no país.\n",
    "  * Estimula a inovação e a formação de profissionais qualificados em áreas estratégicas para o desenvolvimento nacional.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 9) Geração de Imagens com Prompts\n",
    "Utilizando as informações sumarizadas das proposições dos deputados, vamos gerar prompts que possam fazer alusão aos temas e o que está sendo proposto. Use o google Colab para gerar imagens com o modelo \"CompVis/stable-diffusion-v1-4\" para duas proposições de sua escolha. Com essas informações, responda:\n",
    "\n",
    "#### a) Descreva o funcionamento dos modelo de imagem, segundo suas arquiteturas, limitações e vantagens:\n",
    "* Stable Diffusion\n",
    "* DALL-e\n",
    "* MidJourney\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stable Diffusion:\n",
    "É um modelo desenvolvido pela Stability AI, e usa uma abordagem chamada de \"difusão estável\" para criar imagens à partir de descrições textuais. É conhecido por oferecer um level de controle e especificidade para usuários que desejam fazer uma customização detalhada das imagens, normalmente resultando em imagens mais coerentes e com mais detalhes, sendo uma das suas principais vantagens.\n",
    "\n",
    "Inspirado em processos físicos de difusão de particulas e aplicado no contexto de geração de imagens, o modelo inicia com uma imagem ruidosa, e, por meio de várias etapas, remove o ruído de maneira controlada até formar uma imagem final. Diferente de outros modelos, o Stable Diffusion opera em um espaço latente, diferente de outros modelos que operam em um espaço de pixel.\n",
    "\n",
    "Acredito que o modelo seja adequado para terafas onde é necessário um controle mais detalhado sobre a geração de imagem ou onde o fine-tunning dos elementos é crucial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DALL-e\n",
    "É um modelo desenvolvido pela Open AI, e também cria imagens à partir de descrições textuais. DALL-e ganhou atenção por sua capacidade de gerar imagens vívidas e com alta qualidade. Sua principal vantagem é permitir que os usuários gerem imagens de alta qualidade a partir de simples prompts narrativos.\n",
    "\n",
    "Seu destaque é a capacidade de transformar conceitos imaginativos em realidades visuais, sendo o favorito de artístas que buscam dar vida às suas ideias mais extravagantes.\n",
    "\n",
    "O DALL-E usa o transformer para modelar tokens de texto e imagem como um único fluxo de dados, o que acaba gerando dois problemas:\n",
    "\n",
    "* Pixels como tokens de imagem ocupam muita memória\n",
    "* Objetivos de probabilidade priorizam dependências de curto alcance entre pixels\n",
    "\n",
    "Por tanto, a solução do DALL-E para esses problemas foi criar um processo de treinamento em dois estágios:\n",
    "\n",
    "1. Aprendizado do Visual Codebook (Utilizando Autoencoders Discretos Variacionais)\n",
    "2. Aprendizado de Distribuição Prévia (Prior Distribution Learning, que utiliza a architetura Transformer)\n",
    "\n",
    "O modelo é capaz de gerar imagens de alta qualidade e com grande fidelidade ao prompt, sendo uma excelente opção para tarefas criativas e artísticas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MidJourney\n",
    "\n",
    "É desenvolvido por uma equipe de pesquisadores independentes, o MidJourney se destaca por sua interpretações artísticas e a habilidade de misturar estilos e conceitos de maneira única. O modelo é conhecido por sua capacidade de criar imagens altamente estilizadas e com uma estética única, uma das vantagens do modelo é que ele também pode ser utilizado para identificar objetos em uma imagem e oferecer soluções em diferentes áreas, como publicidade e análise de dados em empresas.\n",
    "\n",
    "A especificação do MidJourney é proprietária, mas acredita-se que ele seja baseado em uma arquitetura de rede neural profunda, como o GAN, que é capaz de gerar imagens realistas e de alta qualidade.\n",
    "\n",
    "Ele possui uma particularidade que é funcionar apenas no Discord, o que pode ser uma limitação para alguns usuários, mas para quem utiliza a plataforma, é uma excelente opção para tarefas criativas e artísticas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Utilize diferentes técnicas de “Estilo Visual” e “Composição”, além de exemplos com negative prompting, para gerar 3 versões de imagem para cada proposição e avalie as diferenças entre os resultados (as imagens) e os prompts (as proposições).\n",
    "\n",
    "Verificar arquivo rodrigo_avila_DR4_AT_geracao_imagens.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
