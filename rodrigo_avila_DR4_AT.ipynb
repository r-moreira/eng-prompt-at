{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFNET\n",
    "## Engenharia de Prompts para Ciência de Dados [24E4_4] - AT\n",
    "### Rodrigo Avila - 22/12/2024\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 2: Criação de Textos com LLMs\n",
    "\n",
    "Utilize a sua conta no “poe.com” para gerar um texto curto (2 parágrafos) que explique a Câmara dos Deputados. Execute o mesmo prompt com 3 LLMs diferentes (claude, gemini e chatgpt) e:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Explique as vantagens e desvantagens dos três LLMs escolhidos.\n",
    "\n",
    "Claude:\n",
    "- Vantagens:\n",
    "    - Ética e segurança como foco central: Claude é projetado para minimizar respostas que possam ser prejudiciais ou tóxicas, priorizando interações seguras.\n",
    "    - Foco em compliance: Útil para casos em que a conformidade com regulamentações e padrões éticos é essencial.\n",
    "- Desvantagens:\n",
    "    - Menor flexibilidade em tópicos técnicos: Pode não ser tão robusto quanto ChatGPT ou Gemini em tarefas altamente técnicas.\n",
    "    - Menor capacidade multimodal \n",
    "\n",
    "Gemini:\n",
    "- Vantagens:\n",
    "    - Capacidade multimodal: Gemini pode lidar com entradas de texto e imagem, o que pode ser útil para tarefas que envolvem múltiplos modos de entrada.\n",
    "    - Flexibilidade em tópicos técnicos: Pode ser mais robusto em termos de conhecimento técnico e especializado.\n",
    "    - Indicado em encontrar eventos mais recentes\n",
    "- Desvantagens:\n",
    "    - Menor foco em compliance: Pode gerar respostas que não são adequadas para ambientes regulamentados ou sensíveis.\n",
    "    - Em geral tem menos profundidade nas respostas ao se comparar com ChatGPT\n",
    "\n",
    "ChatGPT:\n",
    "- Vantagens:\n",
    "    - Profundidade nas respostas: ChatGPT pode fornecer respostas mais detalhadas e completas em comparação com outros modelos.\n",
    "    - Versatilidade: É um dos modelos mais amplamente usados, com excelente desempenho em tarefas criativas, técnicas e educacionais.\n",
    "    - Costuma ser melhor na parte criativa\n",
    "- Desvantagens:\n",
    "    - Custos de uso: Em geral, pode ser mais caro de usar em comparação com outros modelos.\n",
    "    - Menor foco em compliance: Pode gerar respostas que não são adequadas para ambientes regulamentados ou sensíveis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Argumente sobre a diferença entre a resposta dos 3 LLMs\n",
    "\n",
    "Claude: Foi o que teve a resposta mais \"rasa\" e menos detalhada, focando mais em aspectos gerais, sem entrar em muitos detalhes específicos.\n",
    "\n",
    "Gemini: Apresentou uma resposta mais detalhada e com mais informações sobre a Câmara dos Deputados, incluindo aspectos como a composição, funções e processos.\n",
    "\n",
    "ChatGPT: Fornecendo uma resposta mais abrangente e detalhada, com uma explicação mais completa sobre a Câmara dos Deputados, acredito que abordou todos os aspectos necessários e importantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Justifique a escolha da resposta final\n",
    "Para o \"use case\" em questão, a melhor resposta foi a do Chat GPT, pois foi uma pergunta bem genérica \"Explique a Câmara dos Deputados\", e nesse caso, acredito que a profundidade da resposta e o detalhamento é o mais importante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Atualize o prompt do LLM final para gerar um arquivo data/config.yaml com a resposta final (chave: overview_summary).\n",
    "Obs: verificar arquivo /data/config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 3: Processamento dos dados de deputados\n",
    "\n",
    "#### a) Colete e salve os dados dos deputados atuais da câmara no arquivo data/deputados.parquet através da url: url_base+/deputados\n",
    "Verificar src/dataprep.py\n",
    "\n",
    "#### b) Executar prompt para criar o código que gere um gráfico de pizza com o total e o percentual de deputados de cada partido, salvo em 'docs/distribuicao_deputados.png\n",
    "Verificar src/dataprep.py\n",
    "\n",
    "#### c) Utilize os elementos de prompts dados, persona e exemplos para instruir o LLM. Explique o objetivo de cada elemento, avalie a resposta e salve-a em data/insights_distribuicao_deputados.json.\n",
    "\n",
    "O objetivo de cada elemento é:\n",
    "\n",
    "- Dados: Ao fornecer os dados sobre a distribuição de deputados por partido e estado, o LLM pode usar essas informações para gerar insights e análises mais precisas e relevantes.\n",
    "- Persona: Ao utilizar um persona, a LLM trás uma resposta especializada, focada em um perfil específico, o que pode ser útil para obter insights mais específicos e detalhados, atendendo melhor a necessidade do usuário.\n",
    "- Exemplos: Utilizado para informar a LLM como seriam os dados e também o formato que ela deveria responder a pergunta (json).\n",
    "\n",
    "Com relação a resposta, acredito que foi bem precisa, dentro do padrão esperado, fornecendo informações relevantes sobre a distribuição de deputados por partido. Não notei nenhuma alucionação, a resposta foi um json válido e bem estruturado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 4: Processamento dos dados de deputados\n",
    "Implemente em dataprep.py uma função que colete as informações das despesas dos deputados atuais da câmara dos deputados no período de referência da solução (use a url: url_base+/deputados/{id}/despesas)\n",
    "\n",
    "#### a) Agrupe os dados de despesas por dia, deputado e tipo de despesa e salve num arquivo parquet (data/serie_despesas_diárias_deputados.parquet).\n",
    "Verificar src/dataprep.py\n",
    "\n",
    "#### b) Utilizando a técnica de prompt-chaining, crie um prompt que instrua o LLM a gerar um código python que analise os dados das despesas dos deputados. Peça para o LLM até 3 análises. Indique ao LLM quais dados estão disponíveis e o respectivo arquivo (salvo em a)) e execute as análises.\n",
    "Verificar prints em images/ex4_prompt_chaining_*.png para visualizar os prompts.\n",
    "\n",
    "Obs: O ChatGPT agora parece ter uma espécie de IDE integrada, bem interessante!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo, execução do código gerado pelo LLM para análise dos dados das despesas dos deputados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"biggest_expense\": {\n",
      "        \"tipoDespesa\": \"LOCAÇÃO OU FRETAMENTO DE AERONAVES\",\n",
      "        \"dataDocumento\": \"2024-09-04T00:00:00\",\n",
      "        \"valorDocumento\": 85000.0,\n",
      "        \"nomeFornecedor\": \"R L FERREIRA - SERVIÇOS E AGENCIAMENTO LTDA\",\n",
      "        \"id\": 220675,\n",
      "        \"nome\": \"Antônio Doido\",\n",
      "        \"siglaPartido\": \"MDB\"\n",
      "    },\n",
      "    \"lowest_expense\": {\n",
      "        \"tipoDespesa\": \"PASSAGEM AÉREA - SIGEPA\",\n",
      "        \"dataDocumento\": \"2024-08-09T12:00:00\",\n",
      "        \"valorDocumento\": -3113.17,\n",
      "        \"nomeFornecedor\": \"TAM\",\n",
      "        \"id\": 74253,\n",
      "        \"nome\": \"Julio Lopes\",\n",
      "        \"siglaPartido\": \"PP\"\n",
      "    },\n",
      "    \"most_frequent_expense\": \"COMBUSTÍVEIS E LUBRIFICANTES.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def analyze_expenses(file_path, output_json_path):\n",
    "    # Read the parquet file into a pandas DataFrame\n",
    "    dataframe = pd.read_parquet(file_path)\n",
    "\n",
    "    # First: Find the expense with the biggest value\n",
    "    biggest_expense = dataframe.loc[dataframe['valorDocumento'].idxmax()]\n",
    "\n",
    "    # Second: Find the expense with the lowest value\n",
    "    lowest_expense = dataframe.loc[dataframe['valorDocumento'].idxmin()]\n",
    "\n",
    "    # Third: Find the most frequent expense type\n",
    "    most_frequent_expense = dataframe['tipoDespesa'].mode()[0]\n",
    "\n",
    "    # Prepare the analysis results with native Python types\n",
    "    analysis = {\n",
    "        \"biggest_expense\": {\n",
    "            \"tipoDespesa\": str(biggest_expense['tipoDespesa']),\n",
    "            \"dataDocumento\": str(biggest_expense['dataDocumento']),\n",
    "            \"valorDocumento\": float(biggest_expense['valorDocumento']),\n",
    "            \"nomeFornecedor\": str(biggest_expense['nomeFornecedor']),\n",
    "            \"id\": int(biggest_expense['id']),\n",
    "            \"nome\": str(biggest_expense['nome']),\n",
    "            \"siglaPartido\": str(biggest_expense['siglaPartido'])\n",
    "        },\n",
    "        \"lowest_expense\": {\n",
    "            \"tipoDespesa\": str(lowest_expense['tipoDespesa']),\n",
    "            \"dataDocumento\": str(lowest_expense['dataDocumento']),\n",
    "            \"valorDocumento\": float(lowest_expense['valorDocumento']),\n",
    "            \"nomeFornecedor\": str(lowest_expense['nomeFornecedor']),\n",
    "            \"id\": int(lowest_expense['id']),\n",
    "            \"nome\": str(lowest_expense['nome']),\n",
    "            \"siglaPartido\": str(lowest_expense['siglaPartido'])\n",
    "        },\n",
    "        \"most_frequent_expense\": str(most_frequent_expense)\n",
    "    }\n",
    "\n",
    "    # Write the analysis to a JSON file\n",
    "    with open(output_json_path, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(analysis, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    return analysis\n",
    "\n",
    "# Define the file paths\n",
    "file_path = 'data/serie_despesas_diárias_deputados.parquet'\n",
    "output_json_path = 'data/despesas_deputados.json'\n",
    "\n",
    "# Perform the analysis\n",
    "results = analyze_expenses(file_path, output_json_path)\n",
    "\n",
    "# Print the analysis results\n",
    "print(json.dumps(results, indent=4, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Utilize os resultados das 3 análises para criar um prompt usando a técnica de Generated Knowledge para instruir o LLM a gerar insights. Salve o resultado como um JSON (data/insights_despesas_deputados.json)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar a imagem ex4_generated_knowledge_1.png para visualizar o prompt.\n",
    "\n",
    "Para a análise gerada, verificar o arquivo data/insights_despesas_deputados.json."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 5) Processamento dos dados de proposições\n",
    "\n",
    "#### a) Coletar um total de 10 proposiçoes por tema e salvar em data/proposicoes_deputados.parquet\n",
    "Verificar src/dataprep.py\n",
    "\n",
    "#### b) Utilize a sumarização por chunks para resumir as proposições tramitadas no período de referência. Avalie a resposta e salve-a em data/sumarizacao_proposicoes.json\n",
    "Verificar src/dataprep.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
